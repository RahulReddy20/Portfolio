const projects = [
  {
    id: 1,
    url: "SafeCityInsights",
    banner: "/projects/Safety/saftey_banner.png",
    img: "/projects/Safety/saftey_banner.png",
    title:
      "SafeCity Insights: Predicting Safety Probabilities by Location and Day",
    imgTitle: "Safety Prediction",
    type: "ML Prediction & Website",
    icon: "/projects/Safety/safety.png",
    blog: "",
    github: "https://github.com/RahulReddy20/Public-Safety/tree/main",
    web: "",
    description:
      "This project provides a new way of predicting safety probabilities. It proposes the usage of a Large Language Model to quantify the severity of crimes, enabling the usage of more datasets (e.g. the Dallas Police Incidents dataset) for safety prediction. Our experiments constitute a comprehensive study of safety prediction in Dallas. This was done through the comparison of numerous models as well as different definitions of the task (classification versus regression). Various aspects were considered such as bias avoidance and ensuring generalizability of our models. Our results have been made accessible through a streamlit app. We provide this study in hopes that it inspires further progress towards a safe, data-driven society",
    tags: [
      {
        name: "Python",
        icon: "/icons/python.png",
        color: "#ffc107fd",
        rgb: "255, 255, 255",
      },
      {
        name: "Scikit Learn",
        icon: "/icons/scikit-learn.png",
        color: "#f5993cfe",
        rgb: "255, 255, 255",
      },
      {
        name: "Pandas",
        icon: "/icons/pandas.png",
        color: "#EFF0F7",
        rgb: "255, 255, 255",
      },
      {
        name: "Streamlit",
        icon: "/icons/streamlit.png",
        color: "#fe4b4c",
        rgb: "255, 255, 255",
      },
    ],

    print: [
      {
        name: "Tabs",
        description:
          "The list of tabs are the different options on the website which can be accessed. They are View Data, Predictions, Visualizations and DataFrame. We will see the different tabs views in the coming photos.",
        img: "/projects/Safety/Tabs.png",
      },
      {
        name: "View Data",
        description:
          'The "View Data" screen shows the processed data which is used to train and build the Machine Learning model which we use. In this case we found the Random Forest Classifier was best suited for the data.',
        img: "/projects/Safety/View-data.png",
      },
      {
        name: "Visualizations",
        description:
          'The "Visualizations" screen shows different visualization graphs which were ploted using the data. The visualization in the image below shows geospatial distribution of crime incidents.',
        img: "/projects/Safety/Visualizations.png",
      },
      {
        name: "Visualizations Options",
        description:
          "On the Visualizations screen we have an option to select from different visualization options some of them are listed in the image shown below.",
        img: "/projects/Safety/Visualizations-options.png",
      },
      {
        name: "Incident Scores Visualization",
        description:
          "The image shown below shows the distribution of incident scores on a bar graph.",
        img: "/projects/Safety/Visualizations2.png",
      },
      {
        name: "Percentage of Crime Visualization",
        description:
          "The image shown below shows the percentage of crime by time bin on a bar graph. Here the time from the data is classified into 4 different bins for better processing of the data.",
        img: "/projects/Safety/Visualizations3.png",
      },
      {
        name: "DataFrame",
        description:
          'The "Dataframe" screen showcases the data count by different data points which are by day, time bin and zipcode. In the image below only the data count by day is shown.',
        img: "/projects/Safety/Dataframe.png",
      },
      {
        name: "Predictions",
        description:
          'The "Predictions" screen offers a form or interface for users to get the safety predictions for a particular zipcode, day, time and month. In the image below we can see that for the selected data the safety prediction is returned as safe.',
        img: "/projects/Safety/Predictions.png",
      },
    ],
    status: "Completed",
    year: "Aug '23 - Dec '23",
    gif: "/projects/Safety/video.mp4",
    backgroundImage: "/projects/Background.png",
    video: "https://www.youtube.com/watch?v=BWU5jvO2xWs",
  },
  {
    id: 4,
    url: "",
    banner: "/projects/Portfolio/portfolio_banner.png",
    img: "/projects/Portfolio/portfolio_banner.png",
    title: "Personal Portfolio",
    imgTitle: "Personal Portfolio",
    type: "Website",
    icon: "/Logo1.png",
    github: "",
    blog: "",
    web: "",
    description:
      "Built using Next.js, a React framework, and incorporating TypeScript for enhanced development, the website boasts a modern and responsive design. The homepage provides a concise introduction about me, highlighting key skills and projects.  The website seamlessly integrates external elements, such as GitHub contributions, to provide a holistic view of your online presence. The inclusion of a contact form, powered by Emailjs, facilitates direct communication, while Calendly integration offers a streamlined process for scheduling meetings. Overall, my personal portfolio website not only reflects technical prowess in web development but also demonstrates a thoughtful curation of content, emphasizing user engagement and accessibility.",
    tags: [
      {
        name: "TypeScript",
        icon: "/icons/TS.png",
        color: "#3178C6",
        rgb: "49, 120, 198",
      },
      {
        name: "React",
        icon: "/icons/react.png",
        color: "#38BDF8",
        rgb: "56, 189, 248",
      },
      {
        name: "Next.js",
        icon: "/icons/nextjs.png",
        color: "#FFFFFF",
        rgb: "255, 255, 255",
      },
      {
        name: "Vercel",
        icon: "/icons/vercel.png",
        color: "#38BDF8",
        rgb: "56, 189, 248",
      },
    ],
    print: [],
    status: "Completed",
    year: "October 2023",
    gif: "",
    backgroundImage: "/projects/Background.png",
    video: "",
  },
  {
    id: 2,
    url: "",
    banner: "/projects/GroceryStore/grocery_banner.png",
    img: "/projects/GroceryStore/grocery_banner.png",
    title: "Grocery Store",
    imgTitle: "Grocery Store",
    type: "Website",
    icon: "/projects/GroceryStore/grocery_icon.webp",
    blog: "",
    github: "",
    web: "",
    description:
      "This project is built from scratch without using any libraries. It is built using HTML, CSS, and JavaScript on the frontend and PHP on the backend. We also use the MySql to connect the database to the website which is hosted locally.",
    tags: [
      {
        name: "HTML",
        icon: "/icons/HTML.png",
        color: "#fc4503",
        rgb: "255, 255, 255",
      },
      {
        name: "CSS",
        icon: "/icons/CSS.png",
        color: "#0328fc",
        rgb: "255, 255, 255",
      },
      {
        name: "JavaScript",
        icon: "/icons/JS.png",
        color: "#fefe01",
        rgb: "255, 255, 255",
      },
      {
        name: "PHP",
        icon: "/icons/php.png",
        color: "#7d8ebd",
        rgb: "255, 255, 255",
      },
      {
        name: "MySQL",
        icon: "/icons/mysql.png",
        color: "#015f8bf6",
        rgb: "255, 255, 255",
      },
    ],
    print: [],
    status: "Completed",
    year: "",
    gif: "",
    backgroundImage: "",
    video: "",
  },
  {
    id: 3,
    url: "",
    banner: "/projects/FaceDetection/face_detection_banner.png",
    img: "/projects/FaceDetection/face_detection_banner.png",
    title: "Real Time Face Detection",
    imgTitle: "Face Detection",
    type: "Computer Vision",
    icon: "/projects/FaceDetection/face_detection.webp",
    github: "",
    blog: "",
    web: "",
    description:
      "The Real-Time Face Detection and Reporting System, developed using Python, showcases a cutting-edge fusion of the haarcascade classifier and YOLOv5 model, enabling swift and accurate face detection in live video streams. Boasting a notable 63% confidence rate, the system underscores its efficacy in real-world scenarios. Beyond its current achievements, the project is in a phase of continual enhancement, focusing on the fine-tuning of hyperparameters to further elevate its precision and adaptability. Positioned for scalability, future prospects include expanding its applications to domains like surveillance and security, affirming its role as a dynamic and forward-looking solution in the realm of computer vision.",
    tags: [
      {
        name: "Python",
        icon: "/icons/python.png",
        color: "#ffc107fd",
        rgb: "255, 255, 255",
      },
      {
        name: "Scikit Learn",
        icon: "/icons/scikit-learn.png",
        color: "#f5993cfe",
        rgb: "255, 255, 255",
      },
      {
        name: "OpenCV",
        icon: "/icons/opencv.png",
        color: "#9b0303fc",
        rgb: "255, 255, 255",
      },
    ],
    print: [],
    status: "Completed",
    year: "November 2023",
    gif: "",
    backgroundImage: "/projects/Background.png",
    video: "https://youtu.be/oh0n2WFNn5U",
  },

  {
    id: 5,
    url: "",
    banner: "/projects/TextSummarization/text_summarization_banner.png",
    img: "/projects/TextSummarization/text_summarization_banner.png",
    title: "Abstractive Text Summarization Using Natural Language Processing",
    imgTitle: "Text Summarization",
    type: "NLP",
    icon: "/projects/TextSummarization/text_summarization.webp",
    github: "",
    blog: "",
    web: "",
    description:
      "Engaging in the Abstractive Text Summarization Using Natural Language Processing project, our collaborative efforts were dedicated to advancing text summarization techniques through the lens of Python and PyTorch. Our approach leveraged the innovative JEANS (Joint Entity and Summary Generation) methodology, complemented by the sophisticated BART model. A unique emphasis was placed on preserving factual consistency within the summaries, steering away from mere replication of original outputs. This project not only delved into the cutting-edge applications of abstractive summarization but also prioritized the nuanced task of ensuring content accuracy, contributing to the evolution of natural language processing capabilities.",
    tags: [
      {
        name: "Python",
        icon: "/icons/python.png",
        color: "#ffc107fd",
        rgb: "255, 255, 255",
      },
      {
        name: "NLTK",
        icon: "/icons/nltk.png",
        color: "#154f5bfe",
        rgb: "255, 255, 255",
      },
      {
        name: "Pytorch",
        icon: "/icons/Pytorch.png",
        color: "#ef4b28",
        rgb: "255, 255, 255",
      },
      {
        name: "Hugging Face",
        icon: "/icons/hugging_face.png",
        color: "#ffd11e",
        rgb: "255, 255, 255",
      },
    ],
    print: [],
    status: "Completed",
    year: "October 2023",
    gif: "",
    backgroundImage: "/projects/Background.png",
    video: "",
  },
  {
    id: 6,
    url: "",
    banner: "/projects/SemanticSegmentation/semantic_segmentation_banner.png",
    img: "/projects/SemanticSegmentation/semantic_segmentation_banner.png",
    title: "Semantic Segmentation of Satellite Imagery Using CNN",
    imgTitle: "Semantic Segmentation",
    type: "Computer Vision and Deep Learning",
    icon: "/projects/SemanticSegmentation/satellite_images.webp",
    github: "",
    blog: "",
    web: "",
    description:
      "In the project on Semantic Segmentation of Satellite Imagery Using Convolutional Neural Networks (CNN), our focus was on developing an advanced system for automated interpretation of satellite images. Employing deep learning techniques, particularly CNNs, we aimed to achieve semantic segmentation, enabling the precise classification of different objects and land cover types within satellite imagery. This project spanned a period of dedicated work, leveraging Python and relevant deep learning frameworks. The goal was to enhance the accuracy and efficiency of satellite image analysis, contributing to applications such as urban planning, environmental monitoring, and disaster response. The implementation prioritized the extraction of meaningful information from vast satellite datasets, offering valuable insights for informed decision-making and resource management.",
    tags: [
      {
        name: "Python",
        icon: "/icons/python.png",
        color: "#ffc107fd",
        rgb: "255, 255, 255",
      },
      {
        name: "OpenCV",
        icon: "/icons/opencv.png",
        color: "#9b0303fc",
        rgb: "255, 255, 255",
      },
      {
        name: "Keras",
        icon: "/icons/Keras.png",
        color: "#d10000",
        rgb: "255, 255, 255",
      },
      {
        name: "Scikit Learn",
        icon: "/icons/scikit-learn.png",
        color: "#f5993cfe",
        rgb: "255, 255, 255",
      },
    ],
    print: [],
    status: "Completed",
    year: "October 2023",
    gif: "",
    backgroundImage: "/projects/Background.png",
    video: "",
  },
  {
    id: 7,
    url: "",
    banner: "/projects/SeizureClassification/seizure_classification_banner.png",
    img: "/projects/SeizureClassification/seizure_classification_banner.png",
    title:
      "Preictal and interictal seizure classification using Spectrogram and CNN techniques",
    imgTitle: "Seizure Classification",
    type: "Deep Learning",
    icon: "/projects/SeizureClassification/seizure.png",
    github: "",
    blog: "",
    web: "",
    description:
      "Our project delves into the intricate realm of preictal and interictal seizure differentiation. Leveraging the power of Spectrogram and Convolutional Neural Network (CNN) techniques, we aim to develop a robust classification system capable of discerning patterns indicative of imminent seizures (preictal) and the intervals between seizures (interictal). The Spectrogram analysis allows us to extract temporal and frequency features from electroencephalogram (EEG) data, providing a comprehensive view of seizure-related dynamics. Coupled with CNN, a powerful deep learning architecture, our approach seeks to enhance the accuracy and efficiency of seizure classification, holding significant promise for improved diagnosis and treatment strategies in the realm of epilepsy research.",
    tags: [
      {
        name: "Python",
        icon: "/icons/python.png",
        color: "#ffc107fd",
        rgb: "255, 255, 255",
      },
      {
        name: "TensorFlow",
        icon: "/icons/Tensorflow.png",
        color: "#ea7524",
        rgb: "255, 255, 255",
      },
      {
        name: "Keras",
        icon: "/icons/Keras.png",
        color: "#d10000",
        rgb: "255, 255, 255",
      },
      {
        name: "Matplotlib",
        icon: "/icons/matplotlib.webp",
        color: "#16577dfa",
        rgb: "255, 255, 255",
      },
      {
        name: "Scipy",
        icon: "/icons/scipy.svg",
        color: "#0054a6",
        rgb: "255, 255, 255",
      },
    ],
    print: [],
    status: "Completed",
    year: "October 2023",
    gif: "",
    backgroundImage: "/projects/Background.png",
    video: "",
  },
];

export default projects;
